{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"13sspqiEZwso4NYTbsflpPyNFaVAAxUgr","timestamp":1680963672481},{"file_id":"1RU2D0OfUp9vkpPnZGN1pSUrVtf_HcvPz","timestamp":1672185517864},{"file_id":"1TAAi_szMfWqRfHVfjGSqnGVLr_ztzUM9","timestamp":1670007363628},{"file_id":"1rY7Ln6rEE1pOlfSHCYOVaqt8OvDO35J0","timestamp":1623440015685},{"file_id":"1XTKHiIcvyL5nuldx0HSL_dUa8yopzy_Y","timestamp":1568928635382},{"file_id":"1gUnPS2zuUOUe4YG-2iDm_Y2X5RTkgsGh","timestamp":1556293046020}],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"premium","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["##4.2. Rule based Model (Covisitation Matrix), differentiated by clicks vs carts/orders"],"metadata":{"id":"81NyjiNk9Y6c"}},{"cell_type":"markdown","source":["**Changes from previous Rule based model** <br>\n","Most concepts from previous model were retained but modified. Main changes are:\n","- differentiation between clicks and orders/carts\n","- 3 covisitation matrices, each specific to clicks or orders/carts prediction\n","- heavier weight allocated to carts for type_weight, putting more emphasis on carts in predicting future purchases.\n","- use of GPU + Rapids to manage long run time and memory errors.\n","\n","<br>\n","\n","**GPU + Rapids** <br>\n","The earlier model took a long time and had memory error many times. This model is even more computational intensive and needs more powerful memory/computing techniques.\n","\n","This model is run using Google Colab GPU and Nvidia Rapids cuDF. cuDF is a GPU-accelerated data frame which accelerates ML workflows by running the entire training pipeline on GPUs. This helped speed up the running processes. Disadvantages is that GPU available is limited and not free, so there are limited amount of times I could experiment or troubleshoot.\n","\n","\n"],"metadata":{"id":"dL1-piBd-N1m"}},{"cell_type":"markdown","source":["**Set up rapids and GPU**"],"metadata":{"id":"Q-nio3hBDyRx"}},{"cell_type":"code","metadata":{"id":"67T0090Jk2KL","executionInfo":{"status":"ok","timestamp":1681198672770,"user_tz":-480,"elapsed":545,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"outputId":"396657cf-c8a1-4a16-a64c-de36a51e593b","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Run this to check if GPU is used\n","!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Apr 11 07:37:52 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   31C    P0    43W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"B0C8IV5TQnjN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0c896ca9-95bf-414a-b1ca-ccea479761fd","executionInfo":{"status":"ok","timestamp":1681198675359,"user_tz":-480,"elapsed":532,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}}},"source":["# Run this each time to get the RAPIDS-Colab install files and test check GPU\n","!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n","!python rapidsai-csp-utils/colab/pip-install.py\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'rapidsai-csp-utils' already exists and is not an empty directory.\n","Traceback (most recent call last):\n","  File \"/content/rapidsai-csp-utils/colab/pip-install.py\", line 28, in <module>\n","    if ('K80' not in gpu_name):\n","TypeError: a bytes-like object is required, not 'str'\n"]}]},{"cell_type":"markdown","source":["**Prepare files**"],"metadata":{"id":"YIavSFxuD5ot"}},{"cell_type":"code","source":["VER = 2\n","\n","import pandas as pd, numpy as np\n","from tqdm.notebook import tqdm\n","import os, sys, pickle, glob, gc\n","from collections import Counter\n","from pandarallel import pandarallel\n","import cudf, itertools\n","print('We will use RAPIDS version',cudf.__version__)"],"metadata":{"id":"_he7vBScrgvj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681198681738,"user_tz":-480,"elapsed":1922,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"outputId":"6858dda3-fd55-42ec-cf41-4a281d759d32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["We will use RAPIDS version 23.2.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/rmm/__init__.py:56: FutureWarning: Use of 'rmm.RMMNumbaManager' is deprecated and will be removed. 'RMMNumbaManager' now lives in the 'rmm.allocators.numba' sub-module, please update your imports.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/rmm/__init__.py:56: FutureWarning: Use of 'rmm.rmm_cupy_allocator' is deprecated and will be removed. 'rmm_cupy_allocator' now lives in the 'rmm.allocators.cupy' sub-module, please update your imports.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AnIgh-ZpuozC","executionInfo":{"status":"ok","timestamp":1681198687454,"user_tz":-480,"elapsed":3183,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"outputId":"0c319e2c-1dcb-48b1-c658-67122bab3c91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%%time\n","# CACHE FUNCTIONS\n","def read_file(f):\n","    return cudf.DataFrame( data_cache[f] )\n","def read_file_to_cache(f):\n","    df = pd.read_parquet(f)\n","    df.ts = (df.ts/1000).astype('int32')\n","    df['type'] = df['type'].map(type_labels).astype('int8')\n","    return df\n","\n","# CACHE THE DATA ON CPU BEFORE PROCESSING ON GPU\n","data_cache = {}\n","type_labels = {'clicks':0, 'carts':1, 'orders':2}\n","\n","files = glob.glob('/content/drive/MyDrive/0.capstone/covisit_prepare/*_parquet/*')\n","for f in files: data_cache[f] = read_file_to_cache(f)\n","\n","# CHUNK PARAMETERS\n","READ_CT = 5\n","CHUNK = int(np.ceil( len(files)/6))\n","print(f'We will process {len(files)} files, in groups of {READ_CT} and chunks of {CHUNK}.')"],"metadata":{"id":"KMssiRNDsKL-","executionInfo":{"status":"ok","timestamp":1681198714975,"user_tz":-480,"elapsed":26829,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d0fad5d0-aa5a-4aa4-ed4d-30342f1e008f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["We will process 146 files, in groups of 5 and chunks of 25.\n","CPU times: user 32.5 s, sys: 8.6 s, total: 41.1 s\n","Wall time: 26.2 s\n"]}]},{"cell_type":"markdown","source":["**Covisitation 1: \"Carts Orders\" Co-visitation Matrix - Type Weighted**\n","\n","This covisitation pair (\"buy\") assumes that recent covisitation pairs clicks/carts/orders is related to the next carts/orders. Pairs that are carts have the most weight followed by orders then clicks. Also weighted by frequency.\n","- Split into parts to prevent memory errors\n","- Select up to 30 most recent click, cart, orders\n","- Identify pairs that occurred within one day\n","- wgt = frequency of interaction of each pair, weighted by type of aid_y\n","- output top 15 pairs of each aid_x by weight"],"metadata":{"id":"4URxEPzDT_Fl"}},{"cell_type":"code","source":["%%time\n","type_weight = {0:0.5, 1:9, 2:2}\n","\n","# USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n","DISK_PIECES = 2\n","SIZE = 1.86e6/DISK_PIECES\n","\n","# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n","for PART in range(DISK_PIECES):\n","    print()\n","    print('### DISK PART',PART+1)\n","    \n","    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n","    # => OUTER CHUNKS\n","    for j in range(6):\n","        a = j*CHUNK\n","        b = min((j+1)*CHUNK, len(files))\n","        print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n","        \n","        # => INNER CHUNKS\n","        for k in range(a,b,READ_CT):\n","            # READ FILE\n","            df = [read_file(files[k])]\n","            for i in range(1,READ_CT): \n","                if k+i < b: df.append(read_file(files[k+i]))\n","            df = cudf.concat(df,ignore_index=True,axis=0)\n","            df = df.sort_values(['session','ts'],ascending=[True,False])\n","            # USE TAIL OF SESSION\n","            df = df.reset_index(drop=True)\n","            df['n'] = df.groupby('session').cumcount()\n","            df = df.loc[df.n<30].drop('n',axis=1)\n","            # CREATE PAIRS\n","            df = df.merge(df,on='session')\n","            df = df.loc[((df.ts_x - df.ts_y).abs()< 24 * 60 * 60) & (df.aid_x != df.aid_y)]\n","            # MEMORY MANAGEMENT COMPUTE IN PARTS\n","            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n","            # ASSIGN WEIGHTS\n","            df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y','type_y'])\n","            df['wgt'] = df.type_y.map(type_weight)\n","            df = df[['aid_x','aid_y','wgt']]\n","            df.wgt = df.wgt.astype('float32')\n","            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n","            # COMBINE INNER CHUNKS\n","            if k==a: tmp2 = df\n","            else: tmp2 = tmp2.add(df, fill_value=0)\n","            print(k,', ',end='')\n","        print()\n","        # COMBINE OUTER CHUNKS\n","        if a==0: tmp = tmp2\n","        else: tmp = tmp.add(tmp2, fill_value=0)\n","        del tmp2, df\n","        gc.collect()\n","    # CONVERT MATRIX TO DICTIONARY\n","    tmp = tmp.reset_index()\n","    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n","    # SAVE TOP 15\n","    tmp = tmp.reset_index(drop=True)\n","    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n","    tmp = tmp.loc[tmp.n < 15].drop('n',axis=1)\n","    # SAVE PART TO DISK (convert to pandas first uses less memory)\n","    tmp.to_pandas().to_parquet(f'/content/drive/MyDrive/0.capstone/covisit_prepare/top_15_carts_orders_v{VER}_{PART}.parquet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWR5Zn8LeZsd","executionInfo":{"status":"ok","timestamp":1681198787368,"user_tz":-480,"elapsed":68364,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"outputId":"9214c2f0-cb0f-4368-ee40-7ab07b882d41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","### DISK PART 1\n","Processing files 0 thru 24 in groups of 5...\n","0 , 5 , 10 , 15 , 20 , \n","Processing files 25 thru 49 in groups of 5...\n","25 , 30 , 35 , 40 , 45 , \n","Processing files 50 thru 74 in groups of 5...\n","50 , 55 , 60 , 65 , 70 , \n","Processing files 75 thru 99 in groups of 5...\n","75 , 80 , 85 , 90 , 95 , \n","Processing files 100 thru 124 in groups of 5...\n","100 , 105 , 110 , 115 , 120 , \n","Processing files 125 thru 145 in groups of 5...\n","125 , 130 , 135 , 140 , 145 , \n","\n","### DISK PART 2\n","Processing files 0 thru 24 in groups of 5...\n","0 , 5 , 10 , 15 , 20 , \n","Processing files 25 thru 49 in groups of 5...\n","25 , 30 , 35 , 40 , 45 , \n","Processing files 50 thru 74 in groups of 5...\n","50 , 55 , 60 , 65 , 70 , \n","Processing files 75 thru 99 in groups of 5...\n","75 , 80 , 85 , 90 , 95 , \n","Processing files 100 thru 124 in groups of 5...\n","100 , 105 , 110 , 115 , 120 , \n","Processing files 125 thru 145 in groups of 5...\n","125 , 130 , 135 , 140 , 145 , \n","CPU times: user 37.2 s, sys: 9.11 s, total: 46.4 s\n","Wall time: 1min 7s\n"]}]},{"cell_type":"markdown","source":["**Covisitation 2: \"Buy2Buy\" Co-visitation Matrix**\n","\n","This covisitation pair (\"buy-to-buy\") assumes that recent buys (carts/orders) have an impact to the next buys (carts/orders). This is weighted only by frequency of pair interaction.\n","- Split into parts to prevent memory errors\n","- Select up to 30 most recent cart, orders only\n","- Identify pairs that occurred within 14 days\n","- wgt = frequency of interaction of each pair\n","- output top 15 pairs of each aid_x by weight"],"metadata":{"id":"IZsZhESwZGMU"}},{"cell_type":"code","source":["%%time\n","# USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n","DISK_PIECES = 1\n","SIZE = 1.86e6/DISK_PIECES\n","\n","# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n","for PART in range(DISK_PIECES):\n","    print()\n","    print('### DISK PART',PART+1)\n","    \n","    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n","    # => OUTER CHUNKS\n","    for j in range(6):\n","        a = j*CHUNK\n","        b = min((j+1)*CHUNK, len(files))\n","        print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n","        \n","        # => INNER CHUNKS\n","        for k in range(a,b,READ_CT):\n","            # READ FILE\n","            df = [read_file(files[k])]\n","            for i in range(1,READ_CT): \n","                if k+i < b: df.append(read_file(files[k+i]))\n","            df = cudf.concat(df,ignore_index=True,axis=0)\n","            df = df.loc[df['type'].isin([1,2])] # ONLY WANT CARTS AND ORDERS\n","            df = df.sort_values(['session','ts'],ascending=[True,False])\n","            # USE TAIL OF SESSION\n","            df = df.reset_index(drop=True)\n","            df['n'] = df.groupby('session').cumcount()\n","            df = df.loc[df.n<30].drop('n',axis=1)\n","            # CREATE PAIRS\n","            df = df.merge(df,on='session')\n","            df = df.loc[((df.ts_x - df.ts_y).abs()< 14 * 24 * 60 * 60) & (df.aid_x != df.aid_y)] # 14 DAYS\n","            # MEMORY MANAGEMENT COMPUTE IN PARTS\n","            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n","            # ASSIGN WEIGHTS\n","            df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y','type_y'])\n","            df['wgt'] = 1\n","            df = df[['aid_x','aid_y','wgt']]\n","            df.wgt = df.wgt.astype('float32')\n","            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n","            # COMBINE INNER CHUNKS\n","            if k==a: tmp2 = df\n","            else: tmp2 = tmp2.add(df, fill_value=0)\n","            print(k,', ',end='')\n","        print()\n","        # COMBINE OUTER CHUNKS\n","        if a==0: tmp = tmp2\n","        else: tmp = tmp.add(tmp2, fill_value=0)\n","        del tmp2, df\n","        gc.collect()\n","    # CONVERT MATRIX TO DICTIONARY\n","    tmp = tmp.reset_index()\n","    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n","    # SAVE TOP 15\n","    tmp = tmp.reset_index(drop=True)\n","    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n","    tmp = tmp.loc[tmp.n < 15].drop('n',axis=1)\n","    # SAVE PART TO DISK (convert to pandas first uses less memory\n","    tmp.to_pandas().to_parquet(f'/content/drive/MyDrive/0.capstone/covisit_prepare/top_15_buy2buy_v{VER}_{PART}.parquet')"],"metadata":{"id":"RRKmypv8eZvC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681198933424,"user_tz":-480,"elapsed":13096,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"outputId":"b3bbb744-fa50-4b15-c526-a07d1d78058f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","### DISK PART 1\n","Processing files 0 thru 24 in groups of 5...\n","0 , 5 , 10 , 15 , 20 , \n","Processing files 25 thru 49 in groups of 5...\n","25 , 30 , 35 , 40 , 45 , \n","Processing files 50 thru 74 in groups of 5...\n","50 , 55 , 60 , 65 , 70 , \n","Processing files 75 thru 99 in groups of 5...\n","75 , 80 , 85 , 90 , 95 , \n","Processing files 100 thru 124 in groups of 5...\n","100 , 105 , 110 , 115 , 120 , \n","Processing files 125 thru 145 in groups of 5...\n","125 , 130 , 135 , 140 , 145 , \n","CPU times: user 10.3 s, sys: 2.3 s, total: 12.6 s\n","Wall time: 12.6 s\n"]}]},{"cell_type":"markdown","source":["**Covisitation 3 \"Clicks\" Co-visitation Matrix - Time Weighted**\n","\n","This covisitation pair assumes that frequency and recency of each paired interaction (clicks/carts/orders) have an impact on the next click.\n","- Split into parts to prevent memory errors\n","- Select up to 30 most recent click, cart, orders\n","- Identify pairs that occurred within 1 day\n","- wgt = frequency of interaction of each pair, weighted by recency (1 to 4, with 4 being most recent)\n","- output top 20 pairs of each aid_x by weight"],"metadata":{"id":"sBLeM4XTZfDn"}},{"cell_type":"code","source":["%%time\n","# USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n","DISK_PIECES = 2\n","SIZE = 1.86e6/DISK_PIECES\n","\n","# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n","for PART in range(DISK_PIECES):\n","    print()\n","    print('### DISK PART',PART+1)\n","    \n","    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n","    # => OUTER CHUNKS\n","    for j in range(6):\n","        a = j*CHUNK\n","        b = min((j+1)*CHUNK, len(files))\n","        print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n","        \n","        # => INNER CHUNKS\n","        for k in range(a,b,READ_CT):\n","            # READ FILE\n","            df = [read_file(files[k])]\n","            for i in range(1,READ_CT): \n","                if k+i < b: df.append(read_file(files[k+i]))\n","            df = cudf.concat(df,ignore_index=True,axis=0)\n","            df = df.sort_values(['session','ts'],ascending=[True,False])\n","            # USE TAIL OF SESSION\n","            df = df.reset_index(drop=True)\n","            df['n'] = df.groupby('session').cumcount()\n","            df = df.loc[df.n < 30].drop('n',axis=1)\n","            # CREATE PAIRS\n","            df = df.merge(df,on='session')\n","            df = df.loc[((df.ts_x - df.ts_y).abs() < 24 * 60 * 60) & (df.aid_x != df.aid_y)]\n","            # MEMORY MANAGEMENT COMPUTE IN PARTS\n","            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n","            # ASSIGN WEIGHTS\n","            df = df[['session', 'aid_x', 'aid_y','ts_x']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n","            df['wgt'] = 1 + 3*(df.ts_x - 1659304800)/(1662328791-1659304800)\n","            df = df[['aid_x','aid_y','wgt']]\n","            df.wgt = df.wgt.astype('float32')\n","            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n","            # COMBINE INNER CHUNKS\n","            if k==a: tmp2 = df\n","            else: tmp2 = tmp2.add(df, fill_value=0)\n","            print(k,', ',end='')\n","        print()\n","        # COMBINE OUTER CHUNKS\n","        if a==0: tmp = tmp2\n","        else: tmp = tmp.add(tmp2, fill_value=0)\n","        del tmp2, df\n","        gc.collect()\n","    # CONVERT MATRIX TO DICTIONARY\n","    tmp = tmp.reset_index()\n","    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n","    # SAVE TOP 15\n","    tmp = tmp.reset_index(drop=True)\n","    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n","    tmp = tmp.loc[tmp.n < 20].drop('n',axis=1)\n","    # SAVE PART TO DISK (convert to pandas first uses less memory)\n","    tmp.to_pandas().to_parquet(f'/content/drive/MyDrive/0.capstone/covisit_prepare/top_20_clicks_v{VER}_{PART}.parquet')"],"metadata":{"id":"mTMhI6CkeZxg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681199003957,"user_tz":-480,"elapsed":66578,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"outputId":"a13ed660-546a-447b-a602-815b01b14022"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","### DISK PART 1\n","Processing files 0 thru 24 in groups of 5...\n","0 , 5 , 10 , 15 , 20 , \n","Processing files 25 thru 49 in groups of 5...\n","25 , 30 , 35 , 40 , 45 , \n","Processing files 50 thru 74 in groups of 5...\n","50 , 55 , 60 , 65 , 70 , \n","Processing files 75 thru 99 in groups of 5...\n","75 , 80 , 85 , 90 , 95 , \n","Processing files 100 thru 124 in groups of 5...\n","100 , 105 , 110 , 115 , 120 , \n","Processing files 125 thru 145 in groups of 5...\n","125 , 130 , 135 , 140 , 145 , \n","\n","### DISK PART 2\n","Processing files 0 thru 24 in groups of 5...\n","0 , 5 , 10 , 15 , 20 , \n","Processing files 25 thru 49 in groups of 5...\n","25 , 30 , 35 , 40 , 45 , \n","Processing files 50 thru 74 in groups of 5...\n","50 , 55 , 60 , 65 , 70 , \n","Processing files 75 thru 99 in groups of 5...\n","75 , 80 , 85 , 90 , 95 , \n","Processing files 100 thru 124 in groups of 5...\n","100 , 105 , 110 , 115 , 120 , \n","Processing files 125 thru 145 in groups of 5...\n","125 , 130 , 135 , 140 , 145 , \n","CPU times: user 35.9 s, sys: 8.81 s, total: 44.7 s\n","Wall time: 1min 5s\n"]}]},{"cell_type":"code","source":["# FREE MEMORY\n","del data_cache, tmp\n","_ = gc.collect()"],"metadata":{"id":"lnDn6S7veZz6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Rank and choose 20 using rules**"],"metadata":{"id":"VTKlfpHPu_VG"}},{"cell_type":"code","source":["def load_test():    \n","    dfs = []\n","    for e, chunk_file in enumerate(glob.glob('/content/drive/MyDrive/0.capstone/covisit_prepare/test_parquet/*')):\n","        chunk = pd.read_parquet(chunk_file)\n","        chunk.ts = (chunk.ts/1000).astype('int32')\n","        chunk['type'] = chunk['type'].map(type_labels).astype('int8')\n","        dfs.append(chunk)\n","    return pd.concat(dfs).reset_index(drop=True) #.astype({\"ts\": \"datetime64[ms]\"})\n","\n","test_df = load_test()\n","print('Test data has shape',test_df.shape)\n","test_df.head()"],"metadata":{"id":"ZtfhhC-_eZ2e","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1681199077274,"user_tz":-480,"elapsed":1587,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"outputId":"9b240ac8-6205-4fc1-daf6-5ad2b6b6380a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test data has shape (6928123, 4)\n"]},{"output_type":"execute_result","data":{"text/plain":["    session      aid          ts  type\n","0  13399779   110716  1661885147     0\n","1  13399779   738837  1661885164     0\n","2  13399780   557072  1661885147     0\n","3  13399780   770350  1661885172     0\n","4  13399781  1062698  1661885147     0"],"text/html":["\n","  <div id=\"df-42965563-a05b-4cde-8990-dbd45c6a5ca5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>session</th>\n","      <th>aid</th>\n","      <th>ts</th>\n","      <th>type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>13399779</td>\n","      <td>110716</td>\n","      <td>1661885147</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>13399779</td>\n","      <td>738837</td>\n","      <td>1661885164</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13399780</td>\n","      <td>557072</td>\n","      <td>1661885147</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13399780</td>\n","      <td>770350</td>\n","      <td>1661885172</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>13399781</td>\n","      <td>1062698</td>\n","      <td>1661885147</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42965563-a05b-4cde-8990-dbd45c6a5ca5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-42965563-a05b-4cde-8990-dbd45c6a5ca5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-42965563-a05b-4cde-8990-dbd45c6a5ca5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["%%time\n","def pqt_to_dict(df):\n","    return df.groupby('aid_x').aid_y.apply(list).to_dict()\n","# LOAD THREE CO-VISITATION MATRICES\n","top_20_clicks = pqt_to_dict( pd.read_parquet(f'/content/drive/MyDrive/0.capstone/covisit_prepare/top_20_clicks_v{VER}_0.parquet') )\n","for k in range(1,DISK_PIECES): \n","    top_20_clicks.update( pqt_to_dict( pd.read_parquet(f'/content/drive/MyDrive/0.capstone/covisit_prepare/top_20_clicks_v{VER}_{k}.parquet') ) )\n","\n","top_20_buys = pqt_to_dict( pd.read_parquet(f'/content/drive/MyDrive/0.capstone/covisit_prepare/top_15_carts_orders_v{VER}_0.parquet') )\n","for k in range(1,DISK_PIECES): \n","    top_20_buys.update( pqt_to_dict( pd.read_parquet(f'/content/drive/MyDrive/0.capstone/covisit_prepare/top_15_carts_orders_v{VER}_{k}.parquet') ) )\n","\n","top_20_buy2buy = pqt_to_dict( pd.read_parquet(f'/content/drive/MyDrive/0.capstone/covisit_prepare/top_15_buy2buy_v{VER}_0.parquet') )\n","\n","# TOP CLICKS AND ORDERS IN TEST\n","top_clicks = test_df.loc[test_df['type']=='clicks','aid'].value_counts().index.values[:20]\n","top_orders = test_df.loc[test_df['type']=='orders','aid'].value_counts().index.values[:20]\n","\n","print('Here are size of our 3 co-visitation matrices:')\n","print(len(top_20_clicks), len(top_20_buy2buy), len(top_20_buys))"],"metadata":{"id":"qXql-dfmeZ5O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681199191756,"user_tz":-480,"elapsed":108235,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"outputId":"1cc62843-1556-498b-e1f0-b6b489a98245"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Here are size of our 3 co-visitation matrices:\n","1837166 1168768 1837166\n","CPU times: user 1min 47s, sys: 4.73 s, total: 1min 51s\n","Wall time: 1min 47s\n"]}]},{"cell_type":"markdown","source":["**suggest_click (for clicks):**\n","- list of aids (click, cart, orders) by user, ordered by recency\n","- if more than 20 aids, weigh by recency, type and frequency. Return the top 20 most score\n","- if less than 20 aids, use the top_20_clicks co-visitation matrix to get additional selected aids. \n","  - For each aid in the original selected, get the top 20 co-occuring aids that will not be duplicated. \n","  - If still less than 20, get from top 20 most popular clicks from test set.\n","<br><br>\n","\n","**suggest_buy (for carts and orders):**\n","- list of buys (cart and orders only) by user, ordered by recency\n","- also pull the list of aids (click, cart, orders) by user, ordered by recency\n","- if more than 20 buys, weigh by recency, type and frequency. Add to aid's score if it is found in top_20_buy2buy co-visitation matrix. Return the top 20 most score\n","- if less than 20 buys, use the top_20_buy2buy and top_20_buy co-visitation matrix to get additional selected buys.\n","  - For each aid in the original selected, get the top 20 frequent co-occuring buys/aids that will not be duplicated.\n","  - If still less than 20, get from top 20 most popular orders from test set."],"metadata":{"id":"rVK1ROYMqOeS"}},{"cell_type":"code","source":["type_weight_multipliers = {0:0.5, 1:9, 2:2}\n","\n","def suggest_clicks(df):\n","    # USER HISTORY AIDS AND TYPES\n","    aids=df.aid.tolist()\n","    types = df.type.tolist()\n","    unique_aids = list(dict.fromkeys(aids[::-1] ))\n","    # RERANK CANDIDATES USING WEIGHTS\n","    if len(unique_aids) >= 20:\n","        weights=np.logspace(0.1,1,len(aids),base=2, endpoint=True)-1\n","        aids_temp = Counter() \n","        # RERANK BASED ON REPEAT ITEMS AND TYPE OF ITEMS\n","        for aid,w,t in zip(aids,weights,types): \n","            aids_temp[aid] += w * type_weight_multipliers[t]\n","        sorted_aids = [k for k,v in aids_temp.most_common(20)]\n","        return sorted_aids\n","    # USE \"CLICKS\" CO-VISITATION MATRIX\n","    aids2 = list(itertools.chain(*[top_20_clicks[aid] for aid in unique_aids if aid in top_20_clicks]))\n","    # RERANK CANDIDATES\n","    top_aids2 = [aid2 for aid2, cnt in Counter(aids2).most_common(20) if aid2 not in unique_aids]    \n","    result = unique_aids + top_aids2[:20 - len(unique_aids)]\n","    # USE TOP20 TEST CLICKS\n","    return result + list(top_clicks)[:20-len(result)]\n","\n","def suggest_buys(df):\n","    # USER HISTORY AIDS AND TYPES\n","    aids=df.aid.tolist()\n","    types = df.type.tolist()\n","    # UNIQUE AIDS AND UNIQUE BUYS\n","    unique_aids = list(dict.fromkeys(aids[::-1] ))\n","    df_buys = df.loc[test_df['type'].isin([1, 2]), 'aid']\n","    unique_buys = list(dict.fromkeys(df_buys.tolist()[::-1]))\n","    # RERANK CANDIDATES USING WEIGHTS\n","    if len(unique_aids) >= 20:\n","        weights=np.logspace(0.5,1,len(aids),base=2, endpoint=True)-1\n","        aids_temp = Counter() \n","        # RERANK BASED ON REPEAT ITEMS AND TYPE OF ITEMS\n","        for aid,w,t in zip(aids,weights,types): \n","            aids_temp[aid] += w * type_weight_multipliers[t]\n","        # RERANK CANDIDATES USING \"BUY2BUY\" CO-VISITATION MATRIX\n","        aids3 = list(itertools.chain(*[top_20_buy2buy[aid] for aid in unique_buys if aid in top_20_buy2buy]))\n","        for aid in aids3: aids_temp[aid] += 0.1\n","        sorted_aids = [k for k,v in aids_temp.most_common(20)]\n","        return sorted_aids\n","    # USE \"CART ORDER\" CO-VISITATION MATRIX\n","    aids2 = list(itertools.chain(*[top_20_buys[aid] for aid in unique_aids if aid in top_20_buys]))\n","    # USE \"BUY2BUY\" CO-VISITATION MATRIX\n","    aids3 = list(itertools.chain(*[top_20_buy2buy[aid] for aid in unique_buys if aid in top_20_buy2buy]))\n","    # RERANK CANDIDATES\n","    top_aids2 = [aid2 for aid2, cnt in Counter(aids2+aids3).most_common(20) if aid2 not in unique_aids] \n","    result = unique_aids + top_aids2[:20 - len(unique_aids)]\n","    # USE TOP20 TEST ORDERS\n","    return result + list(top_orders)[:20-len(result)]"],"metadata":{"id":"47DTqYApeZ7u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Submission CSV**"],"metadata":{"id":"7xGpKNDTvSGp"}},{"cell_type":"code","source":["%%time\n","\n","# run in parallel\n","pandarallel.initialize()\n","pred_df_clicks = test_df.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).parallel_apply(lambda x: suggest_clicks(x))\n","pred_df_buys = test_df.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).parallel_apply(lambda x: suggest_buys(x))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QX7SBXvivNId","executionInfo":{"status":"ok","timestamp":1681201679516,"user_tz":-480,"elapsed":2200083,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"outputId":"b98d2bd4-5d1f-4a5b-ae58-b0e6d545fe37"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO: Pandarallel will run on 6 workers.\n","INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n","CPU times: user 4min 12s, sys: 28.2 s, total: 4min 40s\n","Wall time: 36min 39s\n"]}]},{"cell_type":"code","source":["clicks_pred_df = pd.DataFrame(pred_df_clicks.add_suffix(\"_clicks\"), columns=[\"labels\"]).reset_index()\n","orders_pred_df = pd.DataFrame(pred_df_buys.add_suffix(\"_orders\"), columns=[\"labels\"]).reset_index()\n","carts_pred_df = pd.DataFrame(pred_df_buys.add_suffix(\"_carts\"), columns=[\"labels\"]).reset_index()"],"metadata":{"id":"ZxFg8ZGgvNLt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_df = pd.concat([clicks_pred_df, orders_pred_df, carts_pred_df])\n","pred_df.columns = [\"session_type\", \"labels\"]\n","pred_df[\"labels\"] = pred_df.labels.apply(lambda x: \" \".join(map(str,x)))\n","pred_df.to_csv(\"/content/drive/MyDrive/0.capstone/for_submission/covisit_hand_rerank_2.csv\", index=False)\n","pred_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"9gN0EFdhvZrN","executionInfo":{"status":"ok","timestamp":1681201773223,"user_tz":-480,"elapsed":40060,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"outputId":"88aa3925-9151-4189-afea-556acc55cdc6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      session_type                                             labels\n","0  12899779_clicks  59625 1253524 737445 438191 731692 1790770 942...\n","1  12899780_clicks  1142000 736515 973453 582732 1502122 889686 48...\n","2  12899781_clicks  918667 199008 194067 57315 141736 1460571 7594...\n","3  12899782_clicks  834354 740494 987399 889671 595994 779477 1274...\n","4  12899783_clicks  1817895 607638 1754419 1216820 1729553 300127 ..."],"text/html":["\n","  <div id=\"df-921cb2ad-6052-43d6-baea-a04285261073\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>session_type</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12899779_clicks</td>\n","      <td>59625 1253524 737445 438191 731692 1790770 942...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>12899780_clicks</td>\n","      <td>1142000 736515 973453 582732 1502122 889686 48...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>12899781_clicks</td>\n","      <td>918667 199008 194067 57315 141736 1460571 7594...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>12899782_clicks</td>\n","      <td>834354 740494 987399 889671 595994 779477 1274...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>12899783_clicks</td>\n","      <td>1817895 607638 1754419 1216820 1729553 300127 ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-921cb2ad-6052-43d6-baea-a04285261073')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-921cb2ad-6052-43d6-baea-a04285261073 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-921cb2ad-6052-43d6-baea-a04285261073');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["**Results** <br>\n","Kaggle score: 0.57650 (Clicks/Carts/Orders = 0.39693 + 0.12658 + 0.05298)\n","\n","Adjusted without scoring weight (meaning scored out of 1), the scores are Clicks (0.53) / Carts (0.42) / Orders (0.66). \n","- It is easier to predict Orders because of the chances clicks/carts will convert to orders as well as their relationship to recent clicks/carts orders.\n","- Clicks performed better than carts probably due to the design of the evaluation: *For clicks there is only a single ground truth value for each session, which is the next aid clicked during the session (although you can still predict up to 20 aid values).*\n","\n","Huge improvement in the score mainly due to\n","- bigger and less chunks for covistation matrix, possible as GPU is able to handle the load (guessing that this could be the biggest factor)\n","- differentiated rules and covisitation matrix for clicks vs carts/orders\n","- fine-tuning of rules (although could experiment further given more resources)"],"metadata":{"id":"x_DHvf_YYQnf"}}]}