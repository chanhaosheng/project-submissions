{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"13sspqiEZwso4NYTbsflpPyNFaVAAxUgr","timestamp":1680963672481},{"file_id":"1RU2D0OfUp9vkpPnZGN1pSUrVtf_HcvPz","timestamp":1672185517864},{"file_id":"1TAAi_szMfWqRfHVfjGSqnGVLr_ztzUM9","timestamp":1670007363628},{"file_id":"1rY7Ln6rEE1pOlfSHCYOVaqt8OvDO35J0","timestamp":1623440015685},{"file_id":"1XTKHiIcvyL5nuldx0HSL_dUa8yopzy_Y","timestamp":1568928635382},{"file_id":"1gUnPS2zuUOUe4YG-2iDm_Y2X5RTkgsGh","timestamp":1556293046020}],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"premium","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["##4.2. Rule based Model (Covisitation Matrix), differentiated by clicks vs carts/orders"],"metadata":{"id":"81NyjiNk9Y6c"}},{"cell_type":"markdown","source":["**Changes from previous Rule based model** <br>\n","Most concepts from previous model were retained but modified. Main changes are:\n","- differentiation between clicks and orders/carts\n","- 3 covisitation matrices, each specific to clicks or orders/carts prediction\n","- heavier weight allocated to carts for type_weight, putting more emphasis on carts in predicting future purchases.\n","- use of GPU + Rapids to manage long run time and memory errors.\n","\n","<br>\n","\n","**GPU + Rapids** <br>\n","The earlier model took a long time and had memory error many times. This model is even more computational intensive and needs more powerful memory/computing techniques.\n","\n","This model is run using Google Colab GPU and Nvidia Rapids cuDF. cuDF is a GPU-accelerated data frame which accelerates ML workflows by running the entire training pipeline on GPUs. This helped speed up the running processes. Disadvantages is that GPU available is limited and not free, so there are limited amount of times I could experiment or troubleshoot.\n","\n","\n"],"metadata":{"id":"dL1-piBd-N1m"}},{"cell_type":"markdown","source":["**Set up rapids and GPU**"],"metadata":{"id":"Q-nio3hBDyRx"}},{"cell_type":"code","metadata":{"id":"67T0090Jk2KL","executionInfo":{"status":"ok","timestamp":1682389005085,"user_tz":-480,"elapsed":8,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"outputId":"441a4ed9-ef55-4152-99fd-9478e07aece3","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Run this to check if GPU is used\n","!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Apr 25 02:16:42 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    45W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"B0C8IV5TQnjN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4f9b182f-514b-456d-91a3-fbdb2c838adb","executionInfo":{"status":"ok","timestamp":1682389305570,"user_tz":-480,"elapsed":289303,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}}},"source":["# Run this each time to get the RAPIDS-Colab install files and test check GPU\n","!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n","!python rapidsai-csp-utils/colab/pip-install.py\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'rapidsai-csp-utils'...\n","remote: Enumerating objects: 385, done.\u001b[K\n","remote: Counting objects: 100% (116/116), done.\u001b[K\n","remote: Compressing objects: 100% (65/65), done.\u001b[K\n","remote: Total 385 (delta 86), reused 51 (delta 51), pack-reused 269\u001b[K\n","Receiving objects: 100% (385/385), 105.74 KiB | 808.00 KiB/s, done.\n","Resolving deltas: 100% (188/188), done.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pynvml\n","  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 7.7 MB/s eta 0:00:00\n","Installing collected packages: pynvml\n","Successfully installed pynvml-11.5.0\n","***********************************************************************\n","Woo! Your instance has the right kind of GPU, a NVIDIA A100-SXM4-40GB!\n","We will now install RAPIDS cuDF, cuML, and cuGraph via pip! \n","Please stand by, should be quick...\n","***********************************************************************\n","\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://pypi.nvidia.com\n","Collecting cudf-cu11\n","  Downloading https://pypi.nvidia.com/cudf-cu11/cudf_cu11-23.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (496.7 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 496.7/496.7 MB 3.1 MB/s eta 0:00:00\n","Collecting cuml-cu11\n","  Downloading https://pypi.nvidia.com/cuml-cu11/cuml_cu11-23.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1111.0 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 GB 1.6 MB/s eta 0:00:00\n","Collecting cugraph-cu11\n","  Downloading https://pypi.nvidia.com/cugraph-cu11/cugraph_cu11-23.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1142.4 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 GB 1.5 MB/s eta 0:00:00\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 58.6 MB/s eta 0:00:00\n","Requirement already satisfied: numba<0.57,>=0.56.4 in /usr/local/lib/python3.9/dist-packages (from cudf-cu11) (0.56.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from cudf-cu11) (23.1)\n","Collecting pyarrow==10.*\n","  Downloading pyarrow-10.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 35.9/35.9 MB 48.3 MB/s eta 0:00:00\n","Requirement already satisfied: cupy-cuda11x<12.0.0a0,>=9.5.0 in /usr/local/lib/python3.9/dist-packages (from cudf-cu11) (11.0.0)\n","Collecting rmm-cu11==23.4.*\n","  Downloading https://pypi.nvidia.com/rmm-cu11/rmm_cu11-23.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 27.8 MB/s eta 0:00:00\n","Collecting nvtx>=0.2.1\n","  Downloading nvtx-0.2.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 441.3/441.3 kB 48.5 MB/s eta 0:00:00\n","Requirement already satisfied: pandas<1.6.0dev0,>=1.3 in /usr/local/lib/python3.9/dist-packages (from cudf-cu11) (1.5.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from cudf-cu11) (4.5.0)\n","Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.9/dist-packages (from cudf-cu11) (1.22.4)\n","Collecting cubinlinker-cu11\n","  Downloading https://pypi.nvidia.com/cubinlinker-cu11/cubinlinker_cu11-0.3.0.post1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.8/8.8 MB 33.0 MB/s eta 0:00:00\n","Collecting cuda-python<12.0,>=11.7.1\n","  Downloading cuda_python-11.8.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.5/16.5 MB 68.4 MB/s eta 0:00:00\n","Collecting protobuf<4.22,>=4.21.6\n","  Downloading protobuf-4.21.12-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 409.8/409.8 kB 48.4 MB/s eta 0:00:00\n","Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from cudf-cu11) (2023.4.0)\n","Collecting ptxcompiler-cu11\n","  Downloading https://pypi.nvidia.com/ptxcompiler-cu11/ptxcompiler_cu11-0.7.0.post1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.8/8.8 MB 28.7 MB/s eta 0:00:00\n","Requirement already satisfied: cachetools in /usr/local/lib/python3.9/dist-packages (from cudf-cu11) (5.3.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.9/dist-packages (from cuml-cu11) (0.12.2)\n","Collecting treelite-runtime==3.2.0\n","  Downloading treelite_runtime-3.2.0-py3-none-manylinux2014_x86_64.whl (198 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 198.2/198.2 kB 28.5 MB/s eta 0:00:00\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from cuml-cu11) (1.10.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.9/dist-packages (from cuml-cu11) (1.2.0)\n","Collecting distributed==2023.3.2.1\n","  Downloading distributed-2023.3.2.1-py3-none-any.whl (957 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 957.1/957.1 kB 74.7 MB/s eta 0:00:00\n","Collecting dask-cuda==23.4.*\n","  Downloading dask_cuda-23.4.0-py3-none-any.whl (125 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 125.3/125.3 kB 20.6 MB/s eta 0:00:00\n","Collecting treelite==3.2.0\n","  Downloading treelite-3.2.0-py3-none-manylinux2014_x86_64.whl (1.0 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 74.1 MB/s eta 0:00:00\n","Collecting dask==2023.3.2\n","  Downloading dask-2023.3.2-py3-none-any.whl (1.2 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 83.6 MB/s eta 0:00:00\n","Collecting dask-cudf-cu11==23.4.*\n","  Downloading https://pypi.nvidia.com/dask-cudf-cu11/dask_cudf_cu11-23.4.1-py3-none-any.whl (79 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.4/79.4 kB 13.8 MB/s eta 0:00:00\n","Collecting raft-dask-cu11==23.4.*\n","  Downloading https://pypi.nvidia.com/raft-dask-cu11/raft_dask_cu11-23.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (215.1 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 215.1/215.1 MB 7.0 MB/s eta 0:00:00\n","Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.9/dist-packages (from dask==2023.3.2->cuml-cu11) (0.12.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from dask==2023.3.2->cuml-cu11) (6.0)\n","Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from dask==2023.3.2->cuml-cu11) (2.2.1)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from dask==2023.3.2->cuml-cu11) (8.1.3)\n","Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from dask==2023.3.2->cuml-cu11) (1.4.0)\n","Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.9/dist-packages (from dask==2023.3.2->cuml-cu11) (6.4.1)\n","Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.9/dist-packages (from dask-cuda==23.4.*->cuml-cu11) (2.2.0)\n","Collecting pynvml<11.5,>=11.0.0\n","  Downloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.0/47.0 kB 7.5 MB/s eta 0:00:00\n","Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (1.0.0)\n","Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.9/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (6.2)\n","Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (1.0.5)\n","Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (1.26.15)\n","Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (1.7.0)\n","Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.9/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (3.1.2)\n","Requirement already satisfied: psutil>=5.7.0 in /usr/local/lib/python3.9/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (5.9.5)\n","Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.9/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (2.4.0)\n","Collecting pylibraft-cu11==23.4.*\n","  Downloading https://pypi.nvidia.com/pylibraft-cu11/pylibraft_cu11-23.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (618.0 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 618.0/618.0 MB 2.7 MB/s eta 0:00:00\n","Collecting ucx-py-cu11==0.31.*\n","  Downloading https://pypi.nvidia.com/ucx-py-cu11/ucx_py_cu11-0.31.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.4 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.4/8.4 MB 25.9 MB/s eta 0:00:00\n","Collecting pylibcugraph-cu11==23.4.*\n","  Downloading https://pypi.nvidia.com/pylibcugraph-cu11/pylibcugraph_cu11-23.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1141.1 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 GB 1.5 MB/s eta 0:00:00\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 269.3/269.3 kB 32.2 MB/s eta 0:00:00\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.2/114.2 kB 19.2 MB/s eta 0:00:00\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 158.8/158.8 kB 24.8 MB/s eta 0:00:00\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp) (2.0.12)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: cython in /usr/local/lib/python3.9/dist-packages (from cuda-python<12.0,>=11.7.1->cudf-cu11) (0.29.34)\n","Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.9/dist-packages (from cupy-cuda11x<12.0.0a0,>=9.5.0->cudf-cu11) (0.8.1)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba<0.57,>=0.56.4->cudf-cu11) (0.39.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba<0.57,>=0.56.4->cudf-cu11) (67.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas<1.6.0dev0,>=1.3->cudf-cu11) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas<1.6.0dev0,>=1.3->cudf-cu11) (2022.7.1)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.9/dist-packages (from yarl<2.0,>=1.0->aiohttp) (3.4)\n","Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.9/dist-packages (from seaborn->cuml-cu11) (3.7.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.13.0->dask==2023.3.2->cuml-cu11) (3.15.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2>=2.10.3->distributed==2023.3.2.1->cuml-cu11) (2.1.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->cuml-cu11) (3.0.9)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->cuml-cu11) (4.39.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->cuml-cu11) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->cuml-cu11) (1.4.4)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->cuml-cu11) (8.4.0)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->cuml-cu11) (5.12.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->cuml-cu11) (1.0.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas<1.6.0dev0,>=1.3->cudf-cu11) (1.16.0)\n","Requirement already satisfied: heapdict in /usr/local/lib/python3.9/dist-packages (from zict>=0.1.3->dask-cuda==23.4.*->cuml-cu11) (1.0.1)\n","Installing collected packages: ptxcompiler-cu11, nvtx, cubinlinker-cu11, pynvml, pyarrow, protobuf, multidict, frozenlist, cuda-python, async-timeout, yarl, ucx-py-cu11, treelite-runtime, treelite, rmm-cu11, dask, aiosignal, pylibraft-cu11, distributed, cudf-cu11, aiohttp, pylibcugraph-cu11, dask-cudf-cu11, dask-cuda, raft-dask-cu11, cuml-cu11, cugraph-cu11\n","  Attempting uninstall: pynvml\n","    Found existing installation: pynvml 11.5.0\n","    Uninstalling pynvml-11.5.0:\n","      Successfully uninstalled pynvml-11.5.0\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 9.0.0\n","    Uninstalling pyarrow-9.0.0:\n","      Successfully uninstalled pyarrow-9.0.0\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","  Attempting uninstall: dask\n","    Found existing installation: dask 2022.12.1\n","    Uninstalling dask-2022.12.1:\n","      Successfully uninstalled dask-2022.12.1\n","  Attempting uninstall: distributed\n","    Found existing installation: distributed 2022.12.1\n","    Uninstalling distributed-2022.12.1:\n","      Successfully uninstalled distributed-2022.12.1\n","ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pandas-gbq 0.17.9 requires pyarrow<10.0dev,>=3.0.0, but you have pyarrow 10.0.1 which is incompatible.\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 cubinlinker-cu11-0.3.0.post1 cuda-python-11.8.1 cudf-cu11-23.4.1 cugraph-cu11-23.4.1 cuml-cu11-23.4.1 dask-2023.3.2 dask-cuda-23.4.0 dask-cudf-cu11-23.4.1 distributed-2023.3.2.1 frozenlist-1.3.3 multidict-6.0.4 nvtx-0.2.5 protobuf-4.21.12 ptxcompiler-cu11-0.7.0.post1 pyarrow-10.0.1 pylibcugraph-cu11-23.4.1 pylibraft-cu11-23.4.1 pynvml-11.4.1 raft-dask-cu11-23.4.1 rmm-cu11-23.4.1 treelite-3.2.0 treelite-runtime-3.2.0 ucx-py-cu11-0.31.1 yarl-1.9.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: cupy-cuda11x in /usr/local/lib/python3.9/dist-packages (11.0.0)\n","Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.9/dist-packages (from cupy-cuda11x) (0.8.1)\n","Requirement already satisfied: numpy<1.26,>=1.20 in /usr/local/lib/python3.9/dist-packages (from cupy-cuda11x) (1.22.4)\n","\n","          ***********************************************************************\n","          The pip install of RAPIDS is complete.\n","          \n","          Please do not run any further installation from the conda based installation methods, as they may cause issues!  \n","          \n","          Please ensure that you're pulling from the git repo to remain updated with the latest working install scripts. \n","r          \n","          Troubleshooting:\n","             - If there is an installation failure, please check back on RAPIDSAI owned templates/notebooks to see how to update your personal files. \n","             - If an installation failure persists when using the latest script, please make an issue on https://github.com/rapidsai-community/rapidsai-csp-utils\n","          ***********************************************************************\n","          \n"]}]},{"cell_type":"markdown","source":["**Prepare files**"],"metadata":{"id":"YIavSFxuD5ot"}},{"cell_type":"code","source":["VER = 5\n","\n","import pandas as pd, numpy as np\n","from tqdm.notebook import tqdm\n","import os, sys, pickle, glob, gc\n","from collections import Counter\n","from pandarallel import pandarallel\n","import cudf, itertools\n","print('We will use RAPIDS version',cudf.__version__)"],"metadata":{"id":"_he7vBScrgvj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682389362504,"user_tz":-480,"elapsed":3111,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"outputId":"5696cf6c-2483-40da-cb88-b9c143ea1f0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["We will use RAPIDS version 23.04.01\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AnIgh-ZpuozC","executionInfo":{"status":"ok","timestamp":1682389455518,"user_tz":-480,"elapsed":38283,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"outputId":"ec6e66e1-7c3a-4a6b-f11b-4a8bb045ecd1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%%time\n","# CACHE FUNCTIONS\n","def read_file(f):\n","    return cudf.DataFrame( data_cache[f] )\n","def read_file_to_cache(f):\n","    df = pd.read_parquet(f)\n","    df.ts = (df.ts/1000).astype('int32')\n","    df['type'] = df['type'].map(type_labels).astype('int8')\n","    return df\n","\n","# CACHE THE DATA ON CPU BEFORE PROCESSING ON GPU\n","data_cache = {}\n","type_labels = {'clicks':0, 'carts':1, 'orders':2}\n","\n","files = glob.glob('/content/drive/MyDrive/0.capstone/covisit_prepare/*_parquet/*')\n","for f in files: data_cache[f] = read_file_to_cache(f)\n","\n","# CHUNK PARAMETERS\n","READ_CT = 5\n","CHUNK = int(np.ceil( len(files)/6))\n","print(f'We will process {len(files)} files, in groups of {READ_CT} and chunks of {CHUNK}.')"],"metadata":{"id":"KMssiRNDsKL-","executionInfo":{"status":"ok","timestamp":1682389563467,"user_tz":-480,"elapsed":89251,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"115c815a-9296-47fa-e8bf-cdbaf0fe6736"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["We will process 146 files, in groups of 5 and chunks of 25.\n","CPU times: user 32.8 s, sys: 9.11 s, total: 41.9 s\n","Wall time: 1min 28s\n"]}]},{"cell_type":"markdown","source":["**Covisitation 1: \"Carts Orders\" Co-visitation Matrix - Type Weighted**\n","\n","This covisitation pair (\"buy\") assumes that recent covisitation pairs clicks/carts/orders is related to the next carts/orders. Pairs that are carts have the most weight followed by orders then clicks. Also weighted by frequency.\n","- Split into parts to prevent memory errors\n","- Select up to 30 most recent click, cart, orders\n","- Identify pairs that occurred within one day\n","- wgt = frequency of interaction of each pair, weighted by type of aid_y\n","- output top 15 pairs of each aid_x by weight"],"metadata":{"id":"4URxEPzDT_Fl"}},{"cell_type":"code","source":["%%time\n","type_weight = {0:0.5, 1:9, 2:2}\n","\n","# USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n","DISK_PIECES = 2\n","SIZE = 1.86e6/DISK_PIECES\n","\n","# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n","for PART in range(DISK_PIECES):\n","    print()\n","    print('### DISK PART',PART+1)\n","    \n","    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n","    # => OUTER CHUNKS\n","    for j in range(6):\n","        a = j*CHUNK\n","        b = min((j+1)*CHUNK, len(files))\n","        print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n","        \n","        # => INNER CHUNKS\n","        for k in range(a,b,READ_CT):\n","            # READ FILE\n","            df = [read_file(files[k])]\n","            for i in range(1,READ_CT): \n","                if k+i < b: df.append(read_file(files[k+i]))\n","            df = cudf.concat(df,ignore_index=True,axis=0)\n","            df = df.sort_values(['session','ts'],ascending=[True,False])\n","            # USE TAIL OF SESSION\n","            df = df.reset_index(drop=True)\n","            df['n'] = df.groupby('session').cumcount()\n","            df = df.loc[df.n<30].drop('n',axis=1)\n","            # CREATE PAIRS\n","            df = df.merge(df,on='session')\n","            df = df.loc[((df.ts_x - df.ts_y).abs()< 24 * 60 * 60) & (df.aid_x != df.aid_y)]\n","            # MEMORY MANAGEMENT COMPUTE IN PARTS\n","            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n","            # ASSIGN WEIGHTS\n","            df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y','type_y'])\n","            df['wgt'] = df.type_y.map(type_weight)\n","            df = df[['aid_x','aid_y','wgt']]\n","            df.wgt = df.wgt.astype('float32')\n","            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n","            # COMBINE INNER CHUNKS\n","            if k==a: tmp2 = df\n","            else: tmp2 = tmp2.add(df, fill_value=0)\n","            print(k,', ',end='')\n","        print()\n","        # COMBINE OUTER CHUNKS\n","        if a==0: tmp = tmp2\n","        else: tmp = tmp.add(tmp2, fill_value=0)\n","        del tmp2, df\n","        gc.collect()\n","    # CONVERT MATRIX TO DICTIONARY\n","    tmp = tmp.reset_index()\n","    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n","    # SAVE TOP 15\n","    tmp = tmp.reset_index(drop=True)\n","    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n","    tmp = tmp.loc[tmp.n < 15].drop('n',axis=1)\n","    # SAVE PART TO DISK (convert to pandas first uses less memory)\n","    tmp.to_pandas().to_parquet(f'/content/drive/MyDrive/0.capstone/covisit_prepare/top_15_carts_orders_v{VER}_{PART}.parquet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWR5Zn8LeZsd","executionInfo":{"status":"ok","timestamp":1682389707037,"user_tz":-480,"elapsed":68294,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"outputId":"aa272ae1-f60c-42c3-98c3-f2c8169fc955"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","### DISK PART 1\n","Processing files 0 thru 24 in groups of 5...\n","0 , 5 , 10 , 15 , 20 , \n","Processing files 25 thru 49 in groups of 5...\n","25 , 30 , 35 , 40 , 45 , \n","Processing files 50 thru 74 in groups of 5...\n","50 , 55 , 60 , 65 , 70 , \n","Processing files 75 thru 99 in groups of 5...\n","75 , 80 , 85 , 90 , 95 , \n","Processing files 100 thru 124 in groups of 5...\n","100 , 105 , 110 , 115 , 120 , \n","Processing files 125 thru 145 in groups of 5...\n","125 , 130 , 135 , 140 , 145 , \n","\n","### DISK PART 2\n","Processing files 0 thru 24 in groups of 5...\n","0 , 5 , 10 , 15 , 20 , \n","Processing files 25 thru 49 in groups of 5...\n","25 , 30 , 35 , 40 , 45 , \n","Processing files 50 thru 74 in groups of 5...\n","50 , 55 , 60 , 65 , 70 , \n","Processing files 75 thru 99 in groups of 5...\n","75 , 80 , 85 , 90 , 95 , \n","Processing files 100 thru 124 in groups of 5...\n","100 , 105 , 110 , 115 , 120 , \n","Processing files 125 thru 145 in groups of 5...\n","125 , 130 , 135 , 140 , 145 , \n","CPU times: user 37.8 s, sys: 9.3 s, total: 47.1 s\n","Wall time: 1min 7s\n"]}]},{"cell_type":"markdown","source":["**Covisitation 2: \"Buy2Buy\" Co-visitation Matrix**\n","\n","This covisitation pair (\"buy-to-buy\") assumes that recent buys (carts/orders) have an impact to the next buys (carts/orders). This is weighted only by frequency of pair interaction.\n","- Split into parts to prevent memory errors\n","- Select up to 30 most recent cart, orders only\n","- Identify pairs that occurred within 7 days (following EDA)\n","- wgt = frequency of interaction of each pair\n","- output top 15 pairs of each aid_x by weight"],"metadata":{"id":"IZsZhESwZGMU"}},{"cell_type":"code","source":["%%time\n","# USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n","DISK_PIECES = 1\n","SIZE = 1.86e6/DISK_PIECES\n","\n","# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n","for PART in range(DISK_PIECES):\n","    print()\n","    print('### DISK PART',PART+1)\n","    \n","    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n","    # => OUTER CHUNKS\n","    for j in range(6):\n","        a = j*CHUNK\n","        b = min((j+1)*CHUNK, len(files))\n","        print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n","        \n","        # => INNER CHUNKS\n","        for k in range(a,b,READ_CT):\n","            # READ FILE\n","            df = [read_file(files[k])]\n","            for i in range(1,READ_CT): \n","                if k+i < b: df.append(read_file(files[k+i]))\n","            df = cudf.concat(df,ignore_index=True,axis=0)\n","            df = df.loc[df['type'].isin([1,2])] # ONLY WANT CARTS AND ORDERS\n","            df = df.sort_values(['session','ts'],ascending=[True,False])\n","            # USE TAIL OF SESSION\n","            df = df.reset_index(drop=True)\n","            df['n'] = df.groupby('session').cumcount()\n","            df = df.loc[df.n<30].drop('n',axis=1)\n","            # CREATE PAIRS\n","            df = df.merge(df,on='session')\n","            df = df.loc[((df.ts_x - df.ts_y).abs()< 7 * 24 * 60 * 60) & (df.aid_x != df.aid_y)] # 7 DAYS\n","            # MEMORY MANAGEMENT COMPUTE IN PARTS\n","            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n","            # ASSIGN WEIGHTS\n","            df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y','type_y'])\n","            df['wgt'] = 1\n","            df = df[['aid_x','aid_y','wgt']]\n","            df.wgt = df.wgt.astype('float32')\n","            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n","            # COMBINE INNER CHUNKS\n","            if k==a: tmp2 = df\n","            else: tmp2 = tmp2.add(df, fill_value=0)\n","            print(k,', ',end='')\n","        print()\n","        # COMBINE OUTER CHUNKS\n","        if a==0: tmp = tmp2\n","        else: tmp = tmp.add(tmp2, fill_value=0)\n","        del tmp2, df\n","        gc.collect()\n","    # CONVERT MATRIX TO DICTIONARY\n","    tmp = tmp.reset_index()\n","    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n","    # SAVE TOP 15\n","    tmp = tmp.reset_index(drop=True)\n","    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n","    tmp = tmp.loc[tmp.n < 15].drop('n',axis=1)\n","    # SAVE PART TO DISK (convert to pandas first uses less memory\n","    tmp.to_pandas().to_parquet(f'/content/drive/MyDrive/0.capstone/covisit_prepare/top_15_buy2buy_v{VER}_{PART}.parquet')"],"metadata":{"id":"RRKmypv8eZvC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682391258635,"user_tz":-480,"elapsed":12061,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"outputId":"bbe49854-3e1b-4753-dc39-211e779d27e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","### DISK PART 1\n","Processing files 0 thru 24 in groups of 5...\n","0 , 5 , 10 , 15 , 20 , \n","Processing files 25 thru 49 in groups of 5...\n","25 , 30 , 35 , 40 , 45 , \n","Processing files 50 thru 74 in groups of 5...\n","50 , 55 , 60 , 65 , 70 , \n","Processing files 75 thru 99 in groups of 5...\n","75 , 80 , 85 , 90 , 95 , \n","Processing files 100 thru 124 in groups of 5...\n","100 , 105 , 110 , 115 , 120 , \n","Processing files 125 thru 145 in groups of 5...\n","125 , 130 , 135 , 140 , 145 , \n","CPU times: user 9.57 s, sys: 2.15 s, total: 11.7 s\n","Wall time: 11.7 s\n"]}]},{"cell_type":"markdown","source":["**Covisitation 3 \"Clicks\" Co-visitation Matrix - Time Weighted**\n","\n","This covisitation pair assumes that frequency and recency of each paired interaction (clicks/carts/orders) have an impact on the next click.\n","- Split into parts to prevent memory errors\n","- Select up to 30 most recent click, cart, orders\n","- Identify pairs that occurred within 1 day\n","- wgt = frequency of interaction of each pair, weighted by recency (1 to 4, with 4 being most recent)\n","- output top 20 pairs of each aid_x by weight"],"metadata":{"id":"sBLeM4XTZfDn"}},{"cell_type":"code","source":["%%time\n","# USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n","DISK_PIECES = 2\n","SIZE = 1.86e6/DISK_PIECES\n","\n","# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n","for PART in range(DISK_PIECES):\n","    print()\n","    print('### DISK PART',PART+1)\n","    \n","    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n","    # => OUTER CHUNKS\n","    for j in range(6):\n","        a = j*CHUNK\n","        b = min((j+1)*CHUNK, len(files))\n","        print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n","        \n","        # => INNER CHUNKS\n","        for k in range(a,b,READ_CT):\n","            # READ FILE\n","            df = [read_file(files[k])]\n","            for i in range(1,READ_CT): \n","                if k+i < b: df.append(read_file(files[k+i]))\n","            df = cudf.concat(df,ignore_index=True,axis=0)\n","            df = df.sort_values(['session','ts'],ascending=[True,False])\n","            # USE TAIL OF SESSION\n","            df = df.reset_index(drop=True)\n","            df['n'] = df.groupby('session').cumcount()\n","            df = df.loc[df.n < 30].drop('n',axis=1)\n","            # CREATE PAIRS\n","            df = df.merge(df,on='session')\n","            df = df.loc[((df.ts_x - df.ts_y).abs() < 24 * 60 * 60) & (df.aid_x != df.aid_y)]\n","            # MEMORY MANAGEMENT COMPUTE IN PARTS\n","            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n","            # ASSIGN WEIGHTS\n","            df = df[['session', 'aid_x', 'aid_y','ts_x']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n","            df['wgt'] = 1 + 3*(df.ts_x - 1659304800)/(1662328791-1659304800)\n","            df = df[['aid_x','aid_y','wgt']]\n","            df.wgt = df.wgt.astype('float32')\n","            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n","            # COMBINE INNER CHUNKS\n","            if k==a: tmp2 = df\n","            else: tmp2 = tmp2.add(df, fill_value=0)\n","            print(k,', ',end='')\n","        print()\n","        # COMBINE OUTER CHUNKS\n","        if a==0: tmp = tmp2\n","        else: tmp = tmp.add(tmp2, fill_value=0)\n","        del tmp2, df\n","        gc.collect()\n","    # CONVERT MATRIX TO DICTIONARY\n","    tmp = tmp.reset_index()\n","    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n","    # SAVE TOP 15\n","    tmp = tmp.reset_index(drop=True)\n","    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n","    tmp = tmp.loc[tmp.n < 20].drop('n',axis=1)\n","    # SAVE PART TO DISK (convert to pandas first uses less memory)\n","    tmp.to_pandas().to_parquet(f'/content/drive/MyDrive/0.capstone/covisit_prepare/top_20_clicks_v{VER}_{PART}.parquet')"],"metadata":{"id":"mTMhI6CkeZxg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682391329191,"user_tz":-480,"elapsed":66947,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"outputId":"4b20310f-d711-4754-9b83-60e2f148438d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","### DISK PART 1\n","Processing files 0 thru 24 in groups of 5...\n","0 , 5 , 10 , 15 , 20 , \n","Processing files 25 thru 49 in groups of 5...\n","25 , 30 , 35 , 40 , 45 , \n","Processing files 50 thru 74 in groups of 5...\n","50 , 55 , 60 , 65 , 70 , \n","Processing files 75 thru 99 in groups of 5...\n","75 , 80 , 85 , 90 , 95 , \n","Processing files 100 thru 124 in groups of 5...\n","100 , 105 , 110 , 115 , 120 , \n","Processing files 125 thru 145 in groups of 5...\n","125 , 130 , 135 , 140 , 145 , \n","\n","### DISK PART 2\n","Processing files 0 thru 24 in groups of 5...\n","0 , 5 , 10 , 15 , 20 , \n","Processing files 25 thru 49 in groups of 5...\n","25 , 30 , 35 , 40 , 45 , \n","Processing files 50 thru 74 in groups of 5...\n","50 , 55 , 60 , 65 , 70 , \n","Processing files 75 thru 99 in groups of 5...\n","75 , 80 , 85 , 90 , 95 , \n","Processing files 100 thru 124 in groups of 5...\n","100 , 105 , 110 , 115 , 120 , \n","Processing files 125 thru 145 in groups of 5...\n","125 , 130 , 135 , 140 , 145 , \n","CPU times: user 36.7 s, sys: 8.85 s, total: 45.6 s\n","Wall time: 1min 6s\n"]}]},{"cell_type":"code","source":["# FREE MEMORY\n","del data_cache, tmp\n","_ = gc.collect()"],"metadata":{"id":"lnDn6S7veZz6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Rank and choose 20 using rules**"],"metadata":{"id":"VTKlfpHPu_VG"}},{"cell_type":"code","source":["def load_test():    \n","    dfs = []\n","    for e, chunk_file in enumerate(glob.glob('/content/drive/MyDrive/0.capstone/covisit_prepare/test_parquet/*')):\n","        chunk = pd.read_parquet(chunk_file)\n","        chunk.ts = (chunk.ts/1000).astype('int32')\n","        chunk['type'] = chunk['type'].map(type_labels).astype('int8')\n","        dfs.append(chunk)\n","    return pd.concat(dfs).reset_index(drop=True) #.astype({\"ts\": \"datetime64[ms]\"})\n","\n","test_df = load_test()\n","print('Test data has shape',test_df.shape)\n","test_df.head()"],"metadata":{"id":"ZtfhhC-_eZ2e","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1682391329926,"user_tz":-480,"elapsed":741,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"outputId":"08f737d9-e57a-4264-f6e2-1931699e6e93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test data has shape (6928123, 4)\n"]},{"output_type":"execute_result","data":{"text/plain":["    session      aid          ts  type\n","0  13399779   110716  1661885147     0\n","1  13399779   738837  1661885164     0\n","2  13399780   557072  1661885147     0\n","3  13399780   770350  1661885172     0\n","4  13399781  1062698  1661885147     0"],"text/html":["\n","  <div id=\"df-571a0369-d1bc-49d7-9184-e9e9e4efa424\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>session</th>\n","      <th>aid</th>\n","      <th>ts</th>\n","      <th>type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>13399779</td>\n","      <td>110716</td>\n","      <td>1661885147</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>13399779</td>\n","      <td>738837</td>\n","      <td>1661885164</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13399780</td>\n","      <td>557072</td>\n","      <td>1661885147</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13399780</td>\n","      <td>770350</td>\n","      <td>1661885172</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>13399781</td>\n","      <td>1062698</td>\n","      <td>1661885147</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-571a0369-d1bc-49d7-9184-e9e9e4efa424')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-571a0369-d1bc-49d7-9184-e9e9e4efa424 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-571a0369-d1bc-49d7-9184-e9e9e4efa424');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["%%time\n","def pqt_to_dict(df):\n","    return df.groupby('aid_x').aid_y.apply(list).to_dict()\n","# LOAD THREE CO-VISITATION MATRICES\n","top_20_clicks = pqt_to_dict( pd.read_parquet(f'/content/drive/MyDrive/0.capstone/covisit_prepare/top_20_clicks_v{VER}_0.parquet') )\n","for k in range(1,DISK_PIECES): \n","    top_20_clicks.update( pqt_to_dict( pd.read_parquet(f'/content/drive/MyDrive/0.capstone/covisit_prepare/top_20_clicks_v{VER}_{k}.parquet') ) )\n","\n","top_20_buys = pqt_to_dict( pd.read_parquet(f'/content/drive/MyDrive/0.capstone/covisit_prepare/top_15_carts_orders_v{VER}_0.parquet') )\n","for k in range(1,DISK_PIECES): \n","    top_20_buys.update( pqt_to_dict( pd.read_parquet(f'/content/drive/MyDrive/0.capstone/covisit_prepare/top_15_carts_orders_v{VER}_{k}.parquet') ) )\n","\n","top_20_buy2buy = pqt_to_dict( pd.read_parquet(f'/content/drive/MyDrive/0.capstone/covisit_prepare/top_15_buy2buy_v{VER}_0.parquet') )\n","\n","# TOP CLICKS AND ORDERS IN TEST\n","top_clicks = test_df.loc[test_df['type']=='clicks','aid'].value_counts().index.values[:20]\n","top_orders = test_df.loc[test_df['type']=='orders','aid'].value_counts().index.values[:20]\n","\n","print('Here are size of our 3 co-visitation matrices:')\n","print(len(top_20_clicks), len(top_20_buy2buy), len(top_20_buys))"],"metadata":{"id":"qXql-dfmeZ5O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682391442350,"user_tz":-480,"elapsed":112435,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"outputId":"e13901c9-6165-491c-eb1c-cd80374d784a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Here are size of our 3 co-visitation matrices:\n","1837166 1158900 1837166\n","CPU times: user 1min 50s, sys: 5 s, total: 1min 55s\n","Wall time: 1min 51s\n"]}]},{"cell_type":"markdown","source":["**suggest_click (for clicks):**\n","- list of aids (click, cart, orders) by user, ordered by recency\n","- if more than 20 aids, weigh by recency, type and frequency. Return the top 20 most score\n","- if less than 20 aids, use the top_20_clicks co-visitation matrix to get additional selected aids. \n","  - For each aid in the original selected, get the top 20 co-occuring aids that will not be duplicated. \n","  - If still less than 20, get from top 20 most popular clicks from test set.\n","<br><br>\n","\n","**suggest_buy (for carts and orders):**\n","- list of buys (cart and orders only) by user, ordered by recency\n","- also pull the list of aids (click, cart, orders) by user, ordered by recency\n","- if more than 20 buys, weigh by recency, type and frequency. Add to aid's score if it is found in top_20_buy2buy co-visitation matrix. Return the top 20 most score\n","- if less than 20 buys, use the top_20_buy2buy and top_20_buy co-visitation matrix to get additional selected buys.\n","  - For each aid in the original selected, get the top 20 frequent co-occuring buys/aids that will not be duplicated.\n","  - If still less than 20, get from top 20 most popular orders from test set."],"metadata":{"id":"rVK1ROYMqOeS"}},{"cell_type":"code","source":["type_weight_multipliers = {0:0.5, 1:9, 2:2}\n","\n","def suggest_clicks(df):\n","    # USER HISTORY AIDS AND TYPES\n","    aids=df.aid.tolist()\n","    types = df.type.tolist()\n","    unique_aids = list(dict.fromkeys(aids[::-1] ))\n","    # RERANK CANDIDATES USING WEIGHTS\n","    if len(unique_aids) >= 20:\n","        weights=np.logspace(0.1,1,len(aids),base=2, endpoint=True)-1\n","        aids_temp = Counter() \n","        # RERANK BASED ON REPEAT ITEMS AND TYPE OF ITEMS\n","        for aid,w,t in zip(aids,weights,types): \n","            aids_temp[aid] += w * type_weight_multipliers[t]\n","        sorted_aids = [k for k,v in aids_temp.most_common(20)]\n","        return sorted_aids\n","    # USE \"CLICKS\" CO-VISITATION MATRIX\n","    aids2 = list(itertools.chain(*[top_20_clicks[aid] for aid in unique_aids if aid in top_20_clicks]))\n","    # RERANK CANDIDATES\n","    top_aids2 = [aid2 for aid2, cnt in Counter(aids2).most_common(20) if aid2 not in unique_aids]    \n","    result = unique_aids + top_aids2[:20 - len(unique_aids)]\n","    # USE TOP20 TEST CLICKS\n","    return result + list(top_clicks)[:20-len(result)]\n","\n","def suggest_buys(df):\n","    # USER HISTORY AIDS AND TYPES\n","    aids=df.aid.tolist()\n","    types = df.type.tolist()\n","    # UNIQUE AIDS AND UNIQUE BUYS\n","    unique_aids = list(dict.fromkeys(aids[::-1] ))\n","    df_buys = df.loc[test_df['type'].isin([1, 2]), 'aid']\n","    unique_buys = list(dict.fromkeys(df_buys.tolist()[::-1]))\n","    # RERANK CANDIDATES USING WEIGHTS\n","    if len(unique_aids) >= 20:\n","        weights=np.logspace(0.5,1,len(aids),base=2, endpoint=True)-1\n","        aids_temp = Counter() \n","        # RERANK BASED ON REPEAT ITEMS AND TYPE OF ITEMS\n","        for aid,w,t in zip(aids,weights,types): \n","            aids_temp[aid] += w * type_weight_multipliers[t]\n","        # RERANK CANDIDATES USING \"BUY2BUY\" CO-VISITATION MATRIX\n","        aids3 = list(itertools.chain(*[top_20_buy2buy[aid] for aid in unique_buys if aid in top_20_buy2buy]))\n","        for aid in aids3: aids_temp[aid] += 0.1\n","        sorted_aids = [k for k,v in aids_temp.most_common(20)]\n","        return sorted_aids\n","    # USE \"CART ORDER\" CO-VISITATION MATRIX\n","    aids2 = list(itertools.chain(*[top_20_buys[aid] for aid in unique_aids if aid in top_20_buys]))\n","    # USE \"BUY2BUY\" CO-VISITATION MATRIX\n","    aids3 = list(itertools.chain(*[top_20_buy2buy[aid] for aid in unique_buys if aid in top_20_buy2buy]))\n","    # RERANK CANDIDATES\n","    top_aids2 = [aid2 for aid2, cnt in Counter(aids2+aids3).most_common(20) if aid2 not in unique_aids] \n","    result = unique_aids + top_aids2[:20 - len(unique_aids)]\n","    # USE TOP20 TEST ORDERS\n","    return result + list(top_orders)[:20-len(result)]"],"metadata":{"id":"47DTqYApeZ7u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Submission CSV**"],"metadata":{"id":"7xGpKNDTvSGp"}},{"cell_type":"code","source":["%%time\n","\n","# run in parallel\n","pandarallel.initialize()\n","pred_df_clicks = test_df.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).parallel_apply(lambda x: suggest_clicks(x))\n","pred_df_buys = test_df.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).parallel_apply(lambda x: suggest_buys(x))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QX7SBXvivNId","executionInfo":{"status":"ok","timestamp":1682393792061,"user_tz":-480,"elapsed":2229299,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"outputId":"d90e6e0a-4238-418d-c780-83f191915bc3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO: Pandarallel will run on 6 workers.\n","INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n","  iterator = iter(dataframe_groupby)\n","/usr/local/lib/python3.9/dist-packages/pandarallel/data_types/dataframe_groupby.py:18: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n","  iterator = iter(dataframe_groupby)\n"]},{"output_type":"stream","name":"stdout","text":["CPU times: user 4min 14s, sys: 28.2 s, total: 4min 42s\n","Wall time: 37min 8s\n"]}]},{"cell_type":"code","source":["clicks_pred_df = pd.DataFrame(pred_df_clicks.add_suffix(\"_clicks\"), columns=[\"labels\"]).reset_index()\n","orders_pred_df = pd.DataFrame(pred_df_buys.add_suffix(\"_orders\"), columns=[\"labels\"]).reset_index()\n","carts_pred_df = pd.DataFrame(pred_df_buys.add_suffix(\"_carts\"), columns=[\"labels\"]).reset_index()"],"metadata":{"id":"ZxFg8ZGgvNLt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_df = pd.concat([clicks_pred_df, orders_pred_df, carts_pred_df])\n","pred_df.columns = [\"session_type\", \"labels\"]\n","pred_df[\"labels\"] = pred_df.labels.apply(lambda x: \" \".join(map(str,x)))\n","# pred_df.to_csv(\"/content/drive/MyDrive/0.capstone/for_submission/covisit_hand_rerank_3.csv\", index=False)\n","pred_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"9gN0EFdhvZrN","executionInfo":{"status":"ok","timestamp":1682393882700,"user_tz":-480,"elapsed":42795,"user":{"displayName":"Timothy Chan","userId":"05163549104732193123"}},"outputId":"4c41830f-a38c-4b9d-e287-ae375fa25ff0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      session_type                                             labels\n","0  12899779_clicks  59625 1253524 737445 438191 731692 1790770 942...\n","1  12899780_clicks  1142000 736515 973453 582732 1502122 889686 48...\n","2  12899781_clicks  918667 199008 194067 57315 141736 1460571 7594...\n","3  12899782_clicks  834354 740494 987399 889671 595994 779477 1274...\n","4  12899783_clicks  1817895 607638 1754419 1216820 1729553 300127 ..."],"text/html":["\n","  <div id=\"df-94075abc-9066-419c-8c06-f58ad2171b92\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>session_type</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12899779_clicks</td>\n","      <td>59625 1253524 737445 438191 731692 1790770 942...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>12899780_clicks</td>\n","      <td>1142000 736515 973453 582732 1502122 889686 48...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>12899781_clicks</td>\n","      <td>918667 199008 194067 57315 141736 1460571 7594...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>12899782_clicks</td>\n","      <td>834354 740494 987399 889671 595994 779477 1274...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>12899783_clicks</td>\n","      <td>1817895 607638 1754419 1216820 1729553 300127 ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94075abc-9066-419c-8c06-f58ad2171b92')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-94075abc-9066-419c-8c06-f58ad2171b92 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-94075abc-9066-419c-8c06-f58ad2171b92');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["**Results** <br>\n","Kaggle score: 0.57648 (Clicks/Carts/Orders = 0.39691 + 0.12658 + 0.05298)\n","\n","Adjusted without scoring weight (meaning scored out of 1), the scores are Clicks (0.53) / Carts (0.42) / Orders (0.66). \n","- It is easier to predict Orders because of the chances clicks/carts will convert to orders as well as their relationship to recent clicks/carts orders.\n","- Clicks performed better than carts probably due to the design of the evaluation: *For clicks there is only a single ground truth value for each session, which is the next aid clicked during the session (although you can still predict up to 20 aid values).*\n","\n","Huge improvement in the score mainly due to\n","- bigger and less chunks for covistation matrix, possible as GPU is able to handle the load (guessing that this could be the biggest factor)\n","- differentiated rules and covisitation matrix for clicks vs carts/orders\n","- fine-tuning of rules (although could experiment further given more resources)"],"metadata":{"id":"x_DHvf_YYQnf"}}]}